{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import cv2\n",
    "import misc.segm.lookup_table as lut\n",
    "from collections import namedtuple\n",
    "import os\n",
    "\n",
    "base_dir = \"/mnt/drive-d/anurag/roadwork/\"\n",
    "scene_data_dir = os.path.join(base_dir, \"scene\")\n",
    "sem_seg_data_dir = os.path.join(scene_data_dir, \"sem_seg\")\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetWorkzoneSemantic(torchvision.datasets.Cityscapes):\n",
    "\n",
    "    CityscapesClass = namedtuple(\n",
    "        \"CityscapesClass\",\n",
    "        [\"name\", \"id\", \"train_id\", \"category\", \"category_id\", \"has_instances\", \"ignore_in_eval\", \"color\"],\n",
    "    )\n",
    "\n",
    "    classes = [\n",
    "        CityscapesClass(  'unlabeled'            ,  0 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
    "\n",
    "        CityscapesClass(  'Road'                 ,  1 ,        1 , 'flat'            , 1       , False        , False        , ( 70, 70, 70) ),\n",
    "        CityscapesClass(  'Sidewalk'             ,  2 ,        2 , 'flat'            , 1       , False        , False        , (102,102,156) ),\n",
    "        CityscapesClass(  'Bike Lane'            ,  3 ,        3 , 'flat'            , 1       , False        , False        , (190,153,153) ),\n",
    "        CityscapesClass(  'Off-Road'             ,  4 ,        4 , 'flat'            , 1       , False        , False        , (180,165,180) ),\n",
    "        CityscapesClass(  'Roadside'             ,  5 ,        5 , 'flat'            , 1       , False        , False        , (150,100,100) ),\n",
    "\n",
    "        CityscapesClass(  'Barrier'              ,  6 ,        6 , 'barrier'         , 2       , False        , False        , (246, 116, 185) ),\n",
    "        CityscapesClass(  'Barricade'            ,  7 ,        7 , 'barrier'         , 2       , False        , False        , (248, 135, 182) ),\n",
    "        CityscapesClass(  'Fence'                ,  8 ,        8 , 'barrier'         , 2       , False        , False        , (251, 172, 187) ),\n",
    "\n",
    "        CityscapesClass(  'Police Vehicle'       ,  9 ,        9 , 'vehicle'         , 3       , True         , False        , (255, 68, 51) ),\n",
    "        CityscapesClass(  'Work Vehicle'         ,  10,        10, 'vehicle'         , 3       , True         , False        , (255,104, 66) ),\n",
    "\n",
    "        CityscapesClass(  'Police Officer'       ,  11,        11, 'human'           , 4       , True         , False        , (184, 107, 35) ),\n",
    "        CityscapesClass(  'Worker'               ,  12,        12, 'human'           , 4       , True         , False        , (205, 135, 29) ),\n",
    "\n",
    "        CityscapesClass(  'Cone'                 ,  13,        13, 'object'          , 5       , True         , False        , (30, 119, 179) ),\n",
    "        CityscapesClass(  'Drum'                 ,  14,        14, 'object'          , 5       , True         , False        , (44, 79, 206) ),\n",
    "        CityscapesClass(  'Vertical Panel'       ,  15,        15, 'object'          , 5       , True         , False        , (102, 81, 210) ),\n",
    "        CityscapesClass(  'Tubular Marker'       ,  16,        16, 'object'          , 5       , True         , False        , (170, 118, 213) ),\n",
    "        CityscapesClass(  'Work Equipment'       ,  17,        17, 'object'          , 5       , True         , False        , (214, 154, 219) ),\n",
    "\n",
    "        CityscapesClass(  'Arrow Board'          ,  18,        18, 'guidance'        , 6       , True         , False        , (241, 71, 14) ),\n",
    "        CityscapesClass(  'TTC Sign'             ,  19,        19, 'guidance'        , 6       , True         , False        , (254, 139, 32) ),\n",
    "    ]\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            root,\n",
    "            device,\n",
    "            split: str = \"train\",\n",
    "            mode: str = \"fine\",\n",
    "            target_type = \"semantic\",\n",
    "            transform = None,\n",
    "            target_transform = None,\n",
    "            transforms = None,\n",
    "            small_size = False\n",
    "        ) -> None:\n",
    "        ## don't want to call Cityscapes.__init__\n",
    "        ## instead want to call VisionDataset.__init__\n",
    "        super(DatasetWorkzoneSemantic.__bases__[0], self).__init__(root, transforms, transform, target_transform)\n",
    "        self.mode = \"gtFine\" if mode == \"fine\" else \"gtCoarse\"\n",
    "        self.images_dir = os.path.join(self.root, \"images\", split)\n",
    "        if mode == \"fine\":\n",
    "            self.targets_dir = os.path.join(self.root, \"gtFine\", split)\n",
    "        else:\n",
    "            self.targets_dir = os.path.join(self.root, \"gtCoarse\", split)\n",
    "        self.target_type = [ target_type ]\n",
    "        self.split = split\n",
    "        self.images = []\n",
    "        self.targets = []\n",
    "\n",
    "        # verify_str_arg(mode, \"mode\", (\"fine\", \"coarse\"))\n",
    "        if mode == \"fine\":\n",
    "            valid_modes = (\"train\", \"val\")\n",
    "        else:\n",
    "            valid_modes = (\"train\", \"val\")\n",
    "\n",
    "\n",
    "        for file_name in os.listdir(self.images_dir):\n",
    "            target_types = []\n",
    "            for t in self.target_type:\n",
    "                target_name = \"{}{}\".format(\n",
    "                    os.path.splitext(file_name)[0], self._get_target_suffix(self.mode, t)\n",
    "                )\n",
    "                target_types.append(os.path.join(self.targets_dir, target_name))\n",
    "\n",
    "            self.images.append(os.path.join(self.images_dir, file_name))\n",
    "            self.targets.append(target_types)\n",
    "\n",
    "        self.device = device\n",
    "        # setup lookup tables for class/color conversions\n",
    "        l_key_id, l_key_trainid, l_key_color = self._get_class_properties()\n",
    "        ar_u_key_id = np.asarray(l_key_id, dtype = np.uint8)\n",
    "        ar_u_key_trainid = np.asarray(l_key_trainid, dtype = np.uint8)\n",
    "        ar_u_key_color = np.asarray(l_key_color, dtype = np.uint8)\n",
    "        _, self.th_i_lut_id2trainid = lut.get_lookup_table(\n",
    "            ar_u_key = ar_u_key_id,\n",
    "            ar_u_val = ar_u_key_trainid,\n",
    "            v_val_default = 0,  # default class is 0 - unlabeled\n",
    "            device = self.device,\n",
    "        )\n",
    "        _, self.th_i_lut_trainid2id = lut.get_lookup_table(\n",
    "            ar_u_key = ar_u_key_trainid,\n",
    "            ar_u_val = ar_u_key_id,\n",
    "            v_val_default = 0,  # default class is 0 - unlabeled\n",
    "            device = self.device,\n",
    "        )\n",
    "        _, self.th_i_lut_trainid2color = lut.get_lookup_table(\n",
    "            ar_u_key = ar_u_key_trainid,\n",
    "            ar_u_val = ar_u_key_color,\n",
    "            v_val_default = 0,  # default color is black\n",
    "            device = self.device,\n",
    "        )\n",
    "    \n",
    "    def _get_target_suffix(self, mode: str, target_type: str) -> str:\n",
    "        if target_type == \"instance\":\n",
    "            return f\"_instanceIds.png\"\n",
    "        elif target_type == \"semantic\":\n",
    "            return f\"_labelIds.png\"\n",
    "        elif target_type == \"color\":\n",
    "            return f\"_color.png\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown value '{target_type}' for argument target_type.\")\n",
    "\n",
    "    def _get_class_properties(self):\n",
    "        # iterate over named tuples (nt)\n",
    "        l_key_id = list()\n",
    "        l_key_trainid = list()\n",
    "        l_key_color = list()\n",
    "        # append classes\n",
    "        for nt_class in self.classes:\n",
    "            if nt_class.train_id in [-1, 255]:\n",
    "                continue\n",
    "            l_key_id.append([nt_class.id])\n",
    "            l_key_trainid.append([nt_class.train_id])\n",
    "            l_key_color.append(nt_class.color)\n",
    "        # append class background\n",
    "        l_key_id.append([0])\n",
    "        l_key_trainid.append([0])\n",
    "        l_key_color.append([0, 0, 0])\n",
    "        return l_key_id, l_key_trainid, l_key_color\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # read images\n",
    "        p_image = self.images[index]\n",
    "        p_target = self.targets[index][0]  # 0 is index of semantic target type\n",
    "        image = cv2.imread(p_image)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        target = cv2.imread(p_target, cv2.IMREAD_UNCHANGED)\n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image = image, mask = target)\n",
    "            image = transformed[\"image\"]\n",
    "            target = transformed[\"mask\"]\n",
    "        return image, target, p_image, p_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create symlink for images in sem_seg_data_dir\n",
    "import os\n",
    "\n",
    "def im_names(root_dir, split):\n",
    "    train_ims_name = os.listdir(os.path.join(root_dir, split))\n",
    "    train_ims_name = list(filter(lambda x: x.endswith(\"labelIds.png\"), train_ims_name))\n",
    "    train_ims_name = list(map(lambda x: x.replace(\"_labelIds.png\", \".jpg\"), train_ims_name))\n",
    "    return train_ims_name\n",
    "\n",
    "sem_seg_images_dir = os.path.join(sem_seg_data_dir, \"images\")\n",
    "os.makedirs(sem_seg_images_dir, exist_ok = True)\n",
    "os.makedirs(os.path.join(sem_seg_images_dir, \"train\"), exist_ok = True)\n",
    "os.makedirs(os.path.join(sem_seg_images_dir, \"val\"), exist_ok = True)\n",
    "\n",
    "sem_seg_targets_dir = os.path.join(sem_seg_data_dir, \"gtFine\")\n",
    "train_ims_name = im_names(sem_seg_targets_dir, \"train\")\n",
    "val_ims_name = im_names(sem_seg_targets_dir, \"val\")\n",
    "\n",
    "imgs_dir = os.path.join(scene_data_dir, \"images\")\n",
    "\n",
    "for im_name in train_ims_name:\n",
    "    im_path = os.path.join(imgs_dir, im_name)\n",
    "    out_path = os.path.join(sem_seg_images_dir, \"train\", im_name)\n",
    "    if os.path.exists(im_path) and not os.path.exists(out_path):\n",
    "       os.symlink(im_path, out_path)\n",
    "\n",
    "for im_name in val_ims_name:\n",
    "    im_path = os.path.join(imgs_dir, im_name)\n",
    "    out_path = os.path.join(sem_seg_images_dir, \"val\", im_name)\n",
    "    if os.path.exists(im_path) and not os.path.exists(out_path):\n",
    "       os.symlink(im_path, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anurag/anaconda3/envs/roadwork/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeepLabV3Plus(\n",
       "  (encoder): EfficientNetEncoder(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          48, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (3-5): 3 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (6): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (7-9): 3 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (10): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(3, 3), stride=[2, 2], groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (11-15): 5 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (16): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=[1, 1], groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (17-21): 5 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (22): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=960, bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 272, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (23-29): 7 x MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=1632, bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (30): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=1632, bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 448, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "      (31): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          448, 2688, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          2688, 2688, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=2688, bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          2688, 112, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          112, 2688, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          2688, 448, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_swish): MemoryEfficientSwish()\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(1792, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "    (_dropout): Dropout(p=0.4, inplace=False)\n",
       "    (_swish): MemoryEfficientSwish()\n",
       "  )\n",
       "  (decoder): DeepLabV3PlusDecoder(\n",
       "    (aspp): Sequential(\n",
       "      (0): ASPP(\n",
       "        (convs): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ASPPSeparableConv(\n",
       "            (0): SeparableConv2d(\n",
       "              (0): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=448, bias=False)\n",
       "              (1): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            )\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (2): ASPPSeparableConv(\n",
       "            (0): SeparableConv2d(\n",
       "              (0): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), groups=448, bias=False)\n",
       "              (1): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            )\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (3): ASPPSeparableConv(\n",
       "            (0): SeparableConv2d(\n",
       "              (0): Conv2d(448, 448, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), groups=448, bias=False)\n",
       "              (1): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            )\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (4): ASPPPooling(\n",
       "            (0): AdaptiveAvgPool2d(output_size=1)\n",
       "            (1): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (3): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (project): Sequential(\n",
       "          (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SeparableConv2d(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "        (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (up): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n",
       "    (block1): Sequential(\n",
       "      (0): Conv2d(32, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (block2): Sequential(\n",
       "      (0): SeparableConv2d(\n",
       "        (0): Conv2d(304, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=304, bias=False)\n",
       "        (1): Conv2d(304, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(256, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "import yaml\n",
    "\n",
    "model_base_path = \"./models/sem_segm_gps_split/\"\n",
    "model_path = os.path.join(model_base_path, \"DeeplabV3Plus_EfficientNetB4_best_model_epoch_0060_workzone.pth\")\n",
    "config_path =  os.path.join(model_base_path, \"DeeplabV3Plus_EfficientNetB4_workzone.yaml\")\n",
    "config = yaml.safe_load(open(config_path, \"r\"))\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype(\"float32\")\n",
    "\n",
    "preprocess_input = get_preprocessing_fn(\n",
    "    encoder_name = config[\"segmentation_model_backbone\"],\n",
    "    pretrained = config[\"segmentation_pretrained_dataset\"],\n",
    ")\n",
    "\n",
    "transform_full = A.Compose([\n",
    "    A.Resize(width=1280, height=720),\n",
    "    A.Lambda(name = \"image_preprocessing\", image = preprocess_input),\n",
    "    A.PadIfNeeded(736, 1280),\n",
    "    A.Lambda(name = \"to_tensor\", image = to_tensor),\n",
    "])\n",
    "\n",
    "dataset_test = DatasetWorkzoneSemantic(\n",
    "    root = sem_seg_data_dir,\n",
    "    split = \"val\",\n",
    "    mode = \"fine\",\n",
    "    transform = transform_full,\n",
    "    device= device,\n",
    ")\n",
    "\n",
    "model = torch.load(model_path, map_location=device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, target, img_path, target_path = dataset_test.__getitem__(0)\n",
    "\n",
    "## non-tensor version of the image, but padded\n",
    "image = cv2.imread(img_path)\n",
    "transform_padded = A.Compose([\n",
    "    A.Resize(width=1280, height=720),\n",
    "    A.PadIfNeeded(736, 1280),\n",
    "])\n",
    "img_padded = transform_padded(image = image)[\"image\"]\n",
    "\n",
    "with torch.inference_mode():\n",
    "    model_input = torch.from_numpy(img).unsqueeze(0)\n",
    "    model_input = model_input.to(device)\n",
    "    logits = model(model_input)\n",
    "    prediction = logits.argmax(axis = 1)\n",
    "\n",
    "prediction_color = lut.lookup_chw(\n",
    "    td_u_input = prediction.byte(),\n",
    "    td_i_lut = dataset_test.th_i_lut_trainid2color,\n",
    ").permute((1, 2, 0)).cpu().numpy()\n",
    "blend = cv2.addWeighted(img_padded, 0.4, prediction_color, 0.6, 0.0)\n",
    "\n",
    "gt_color = lut.lookup_chw(\n",
    "    td_u_input = torch.from_numpy(target).unsqueeze(0).byte().to(device),\n",
    "    td_i_lut = dataset_test.th_i_lut_trainid2color,\n",
    ").permute((1, 2, 0)).cpu().numpy()\n",
    "gt_blend = cv2.addWeighted(img_padded, 0.4, gt_color, 0.6, 0.0)\n",
    "\n",
    "os.makedirs(\"./output/segm_gps_split/gt\", exist_ok=True)\n",
    "cv2.imwrite(\"./output/segm_gps_split/gt/{img}\".format(img=os.path.basename(img_path)), gt_blend)\n",
    "\n",
    "os.makedirs(\"./output/segm_gps_split/vis\", exist_ok=True)\n",
    "cv2.imwrite(\"./output/segm_gps_split/vis/{img}\".format(img=os.path.basename(img_path)), blend)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roadwork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
